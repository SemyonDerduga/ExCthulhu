"""
–ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –¥–µ–π—Å—Ç–≤–∏–µ –¥–ª—è –ø–æ–∏—Å–∫–∞ –∞—Ä–±–∏—Ç—Ä–∞–∂–∞ —Å –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ–º.
"""

import logging
import asyncio
from collections import defaultdict
from typing import Optional, List

from cthulhu_src.services.exchange_manager import ExchangeManager
from cthulhu_src.services.forecast_arbitrage import ForecastArbitrageService, ArbitrageOpportunity
from cthulhu_src.services.historical_data import MultiExchangeHistoricalService
from cthulhu_src.services.exchanges.batching_exchange import BatchingExchange
from cthulhu_src.services.cross_exchange_manager import get_free_transitions


async def run(
    ctx,
    max_depth: int,
    exchange_list: list,
    start_node: str,
    start_amount: float,
    cache_dir: str,
    historical_prices: Optional[List[float]] = None,
    forecast_method: str = "mean",
    forecast_horizon: int = 5,
    lookback: int = 60,
    auto_fetch_history: bool = False,
    history_hours: int = 24,
    history_symbol: Optional[str] = None,
    cached: bool = False,
    algorithm: str = "dfs",
    processes: Optional[int] = None,
    prune_ratio: float = 0.0,
    batch_size: int = 20,
    proxy: tuple = (),
) -> None:
    """
    –ó–∞–ø—É—Å—Ç–∏—Ç—å –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–æ–∏—Å–∫ –∞—Ä–±–∏—Ç—Ä–∞–∂–∞ —Å –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ–º.
    
    –≠—Ç–∞ –∫–æ–º–∞–Ω–¥–∞:
    1. –ù–∞—Ö–æ–¥–∏—Ç –∞—Ä–±–∏—Ç—Ä–∞–∂–Ω—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏
    2. –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ
    3. –î–µ–ª–∞–µ—Ç –ø—Ä–æ–≥–Ω–æ–∑—ã –¥–≤–∏–∂–µ–Ω–∏—è —Ü–µ–Ω
    4. –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç –¥–µ–π—Å—Ç–≤–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–æ–≥–Ω–æ–∑–æ–≤
    """
    log = logging.getLogger("excthulhu")
    log.info(
        f'üîç –ù–∞—á–∏–Ω–∞–µ–º –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–æ–∏—Å–∫ –∞—Ä–±–∏—Ç—Ä–∞–∂–∞ —Å –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ–º (–≥–ª—É–±–∏–Ω–∞: {max_depth}, –±–∏—Ä–∂–∏: {", ".join(exchange_list)})'
    )

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–µ—Ä–≤–∏—Å–∞ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è
    forecast_service = ForecastArbitrageService(
        lookback=lookback, 
        forecast_method=forecast_method
    )

    # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –ø–æ–ª—É—á–µ–Ω–∏–µ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö
    if auto_fetch_history and not historical_prices:
        log.info("üìä –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø–æ–ª—É—á–∞–µ–º –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ...")
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å–∏–º–≤–æ–ª –¥–ª—è –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö
        if not history_symbol:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –≤–∞–ª—é—Ç—É –∏–∑ start_node (–Ω–∞–ø—Ä–∏–º–µ—Ä, binance_BTC -> BTC/USDT)
            currency = start_node.split('_')[-1] if '_' in start_node else 'BTC'
            history_symbol = f"{currency}/USDT"
        
        try:
            # –ü–æ–ª—É—á–∞–µ–º –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ —Å –ø–µ—Ä–≤–æ–π –±–∏—Ä–∂–∏
            historical_service = MultiExchangeHistoricalService([exchange_list[0]], list(proxy))
            
            historical_prices = await historical_service.services[exchange_list[0]].get_price_history(
                history_symbol, 
                hours=history_hours
            )
            
            await historical_service.close()
            
            if historical_prices:
                log.info(f"‚úÖ –ü–æ–ª—É—á–µ–Ω–æ {len(historical_prices)} –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö —Ü–µ–Ω –¥–ª—è {history_symbol}")
            else:
                log.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è {history_symbol}")
                
        except Exception as e:
            log.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö: {e}")

    log.info("‚¨áÔ∏è –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ —Å –±–∏—Ä–∂...")

    BatchingExchange.max_batch_size = batch_size
    exchange_manager = ExchangeManager(
        exchange_list, proxy, cached=cached, cache_dir=cache_dir
    )
    
    try:
        pairs = await exchange_manager.fetch_prices()
    finally:
        await exchange_manager.close()

    pairs += get_free_transitions(exchange_list)

    log.info("‚úÖ –ó–∞–≥—Ä—É–∑–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞")

    log.info("‚öôÔ∏è –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ...")

    # –°–æ–∑–¥–∞–µ–º –≥—Ä–∞—Ñ –æ–±–º–µ–Ω–Ω—ã—Ö –∫—É—Ä—Å–æ–≤
    adj_dict = defaultdict(list)
    for pair in pairs:
        adj_dict[pair.currency_from].append(pair)

    currency_list = list(adj_dict.keys())

    adj_list = [
        {
            currency_list.index(pair.currency_to): pair.trade_book
            for pair in adj_dict[currency_from]
        }
        for currency_from in currency_list
    ]

    log.info("‚úÖ –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∑–∞–≤–µ—Ä—à–µ–Ω–∞")

    if start_node not in currency_list:
        log.error(f"‚ùå –°—Ç–∞—Ä—Ç–æ–≤–∞—è –≤–∞–ª—é—Ç–∞ {start_node} –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞ –≤ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö.")
        return

    start_node_id = currency_list.index(start_node)

    log.info("üîÑ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ —Å –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ–º...")

    # –ü–æ–∏—Å–∫ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π —Å –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ–º
    opportunities = forecast_service.find_opportunities_with_forecast(
        adj_list=adj_list,
        start_node=start_node_id,
        start_amount=start_amount,
        max_depth=max_depth,
        prune_ratio=prune_ratio,
        num_workers=processes,
        historical_prices=historical_prices,
        forecast_horizon=forecast_horizon,
    )

    # –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    log.info(f"üìä –ù–∞–π–¥–µ–Ω–æ {len(opportunities)} –∞—Ä–±–∏—Ç—Ä–∞–∂–Ω—ã—Ö –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π")

    if not opportunities:
        log.info("‚ùå –ü—Ä–∏–±—ã–ª—å–Ω—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
        return

    # –ê–Ω–∞–ª–∏–∑ —Ä—ã–Ω–æ—á–Ω—ã—Ö —Ç—Ä–µ–Ω–¥–æ–≤ –µ—Å–ª–∏ –µ—Å—Ç—å –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ
    if historical_prices:
        log.info("üìà –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä—ã–Ω–æ—á–Ω—ã–µ —Ç—Ä–µ–Ω–¥—ã...")
        trend_analysis = forecast_service.analyze_market_trends(historical_prices)
        
        if "error" not in trend_analysis:
            trend = trend_analysis.get("overall_trend", "neutral")
            log.info(f"üìä –û–±—â–∏–π —Ç—Ä–µ–Ω–¥ —Ä—ã–Ω–∫–∞: {trend}")
        else:
            log.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —Ç—Ä–µ–Ω–¥–æ–≤: {trend_analysis['error']}")

    # –í—ã–≤–æ–¥–∏–º —Ç–æ–ø-5 –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π
    log.info("üèÜ –¢–æ–ø-5 –∞—Ä–±–∏—Ç—Ä–∞–∂–Ω—ã—Ö –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π:")
    
    for i, opportunity in enumerate(opportunities[:5], 1):
        log.info(f"\n{i}. –ü—É—Ç—å: {' -> '.join([f'{node[0]}' for node in opportunity.path])}")
        log.info(f"   üí∞ –ü—Ä–∏–±—ã–ª—å: {opportunity.profit_percent:.2f}%")
        
        if opportunity.forecast:
            log.info(f"   üìà –ü—Ä–æ–≥–Ω–æ–∑: {opportunity.forecast.mu:.4f} (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {opportunity.forecast_confidence:.2f})")
            log.info(f"   üéØ –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è: {opportunity.recommended_action}")
        else:
            log.info(f"   üìà –ü—Ä–æ–≥–Ω–æ–∑: –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω (–Ω–µ—Ç –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö)")

    log.info(f"\n‚úÖ –ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–æ–∏—Å–∫ –∑–∞–≤–µ—Ä—à–µ–Ω. –ù–∞–π–¥–µ–Ω–æ {len(opportunities)} –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π.") 